---
layout: home

hero:
  name: ContextOS
  text: The Context Server Protocol for AI Coding
  tagline: Stop paying for noise. Curate your context.
  image:
    src: /logo.svg
    alt: ContextOS
  actions:
    - theme: brand
      text: Get Started
      link: /guide/getting-started
    - theme: alt
      text: View on GitHub
      link: https://github.com/contextos/contextos

features:
  - icon: ðŸ§ 
    title: RLM Engine
    details: Recursive Language Model engine based on MIT CSAIL research. Context as an external, queryable environment.
  - icon: ðŸ”—
    title: Dependency Graph
    details: Automatic dependency analysis across 6 languages - TypeScript, JavaScript, Python, Go, Rust, Java.
  - icon: ðŸ“Š
    title: Hybrid Ranking
    details: Combines semantic similarity, graph distance, and custom rules for optimal context selection.
  - icon: ðŸ¤–
    title: Multi-Model Support
    details: Works with Gemini 3, GPT-5, Claude 4.5 and more. Unified adapter interface.
  - icon: ðŸ”’
    title: Safe Refactoring
    details: Transaction layer with conflict detection. Proposals instead of direct writes.
  - icon: âš¡
    title: Token Optimization
    details: Reduce token usage by 50-70% while maintaining context quality.
---

## Quick Start

```bash
# Install globally
npm install -g @contextos/cli

# Initialize your project
cd your-project
ctx init

# Build context for your goal
ctx goal "Add authentication to API"

# Copy optimized context
ctx copy
```

## Why ContextOS?

| Traditional Approach | ContextOS |
|---------------------|-----------|
| ðŸ’¸ Paste entire codebase â†’ Token waste | ðŸ“Š Hybrid ranking â†’ Optimal selection |
| â° Manual file selection â†’ Time consuming | ðŸ¤– AI-powered â†’ Automatic |
| ðŸŽ¯ Let AI guess â†’ Wrong context | ðŸ”— Dependency graph â†’ Complete context |

## Powered by Research

ContextOS implements the **Recursive Language Model (RLM)** paradigm from MIT CSAIL:

> "Instead of treating context as static input, RLM treats it as an external environment that can be queried programmatically."

[Read the RLM Paper â†’](/rlm/how-it-works)
